{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "style transfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgU8YW9QszI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "np.savetxt(\"historycost.csv\", [0, 0], delimiter=\",\") #to save cost during multiple training times due to limited Ressources: RAM, ...\n",
        "historyCost = np.genfromtxt('historycost.csv', delimiter=',').tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3XtIwkKWRWU"
      },
      "source": [
        "#utils\n",
        "def clip_0_1(image):\n",
        "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor * 255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor) > 3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return Image.fromarray(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koUavDsXUWG7"
      },
      "source": [
        "#Hyperparams\n",
        "\n",
        "img_size = 200\n",
        "learning_rate = 0.001 #low learning tend to give better result in this case but slower :')\n",
        "style_weight=10\n",
        "content_weight=40\n",
        "beta_1=0.99\n",
        "epsilon=1e-1\n",
        "\n",
        "#choosen layers for style & content (see the model layers in its summary)\n",
        "STYLE_LAYERS = [\n",
        "    ('block1_conv1', 0.2),\n",
        "    ('block2_conv1', 0.2),\n",
        "    ('block3_conv1', 0.2),\n",
        "    ('block4_conv1', 0.2),\n",
        "    ('block5_conv1', 0.2)]\n",
        "content_layer = [('block5_conv4', 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXO1RxMXQszg"
      },
      "source": [
        "#Load images\n",
        "content_image = np.array(Image.open(\"mosque.jpg\").resize((img_size, img_size)))\n",
        "content_image = tf.constant(np.reshape(content_image, ((1,) + content_image.shape)))\n",
        "\n",
        "style_image =  np.array(Image.open(\"starry_night_full.jpg\").resize((img_size, img_size)))\n",
        "style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n",
        "\n",
        "fig = plt.figure(figsize=(16, 4))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "imshow(content_image[0])\n",
        "ax.title.set_text('Content image')\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "imshow(style_image[0])\n",
        "ax.title.set_text('Style image')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqFZF_aMQszM"
      },
      "source": [
        "#Loading the model\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "vgg = tf.keras.applications.VGG19(include_top=False,\n",
        "                                  input_shape=(img_size, img_size, 3),\n",
        "                                  weights='imagenet')\n",
        "\n",
        "vgg.trainable = False\n",
        "pp.pprint(vgg)\n",
        "vgg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqPRhVLLQszQ"
      },
      "source": [
        "\n",
        "$$J_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2\\tag{1} $$\n",
        "\n",
        "\n",
        "\n",
        "$$J_{style}^{[l]}(S,G) = \\frac{1}{4 \\times {n_C}^2 \\times (n_H \\times n_W)^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2\\tag{2} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3d3bfd0678816054",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "XtlmMinpQszR"
      },
      "source": [
        "#calculations: cost, Gram...\n",
        "def compute_content_cost(content_output, generated_output):\n",
        "    a_C = content_output[-1]\n",
        "    a_G = generated_output[-1]\n",
        "    \n",
        "    m, n_H, n_W, n_C = a_C.get_shape().as_list()\n",
        "\n",
        "    a_C_unrolled = tf.transpose( tf.reshape(a_C, shape=[m, -1, n_C] ) )\n",
        "    a_G_unrolled = tf.transpose( tf.reshape(a_G, shape=[m, -1, n_C] ) )\n",
        "    J_content = (1/4/n_C/n_H/n_W) * tf.reduce_sum(tf.square(a_C_unrolled - a_G_unrolled))\n",
        "    \n",
        "    return J_content\n",
        "\n",
        "def gram_matrix(A):\n",
        "    GA = tf.linalg.matmul(A, tf.transpose(A))\n",
        "    return GA\n",
        "\n",
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    \n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    a_S = tf.transpose( tf.reshape(a_S, shape=[n_H*n_W, n_C] ) )\n",
        "    a_G = tf.transpose( tf.reshape(a_G, shape=[n_H*n_W, n_C] ) )\n",
        "    GS = gram_matrix(a_S)\n",
        "    GG = gram_matrix(a_G)\n",
        "    \n",
        "    J_style_layer = ( 1/(4 * n_C**2 *(n_H*n_W)**2 )  ) * tf.reduce_sum(tf.reduce_sum( tf.square( tf.subtract( GS,GG ) ) ) )\n",
        "        \n",
        "    return J_style_layer\n",
        "\n",
        "def compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):\n",
        "    J_style = 0\n",
        "    a_S = style_image_output[:-1]\n",
        "    a_G = generated_image_output[:-1]\n",
        "    \n",
        "    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  \n",
        "        # Compute style_cost for the current layer\n",
        "        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])\n",
        "\n",
        "        # Add weight * J_style_layer of this layer to overall style cost\n",
        "        J_style += weight[1] * J_style_layer\n",
        "\n",
        "    return J_style"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fpm7ZYOTUXj"
      },
      "source": [
        "# Total cost\n",
        "@tf.function()\n",
        "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
        "    return alpha*J_content + beta*J_style"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV11sp-3Qsza"
      },
      "source": [
        "#VGG model layer names\n",
        "for layer in vgg.layers:\n",
        "    print(layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7bGVpvpQszj"
      },
      "source": [
        "def get_layer_outputs(vgg, layer_names):\n",
        "    \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
        "    outputs = [vgg.get_layer(layer[0]).output for layer in layer_names]\n",
        "\n",
        "    model = tf.keras.Model([vgg.input], outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXyvbKbGQszk"
      },
      "source": [
        "vgg_model_outputs = get_layer_outputs(vgg, STYLE_LAYERS + content_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFY-bmDiQszk"
      },
      "source": [
        "content_target = vgg_model_outputs(content_image)  \n",
        "style_targets = vgg_model_outputs(style_image)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt-UFsgSQszl"
      },
      "source": [
        "#calculating style & content output to be used in the training\n",
        "\n",
        "preprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
        "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
        "a_S = vgg_model_outputs(preprocessed_style)\n",
        "a_C = vgg_model_outputs(preprocessed_content)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-dfbcc4b8f8a959e5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "jkprBbUEQszn"
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1 =beta_1, epsilon= epsilon)\n",
        "\n",
        "#total_variation_weight = 30\n",
        "\n",
        "@tf.function()\n",
        "def train_step(generated_image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        a_G = vgg_model_outputs(generated_image)\n",
        "\n",
        "        J_style = compute_style_cost(a_S, a_G, STYLE_LAYERS=STYLE_LAYERS)\n",
        "        J_content = compute_content_cost(a_C, a_G)\n",
        "        # Compute the total cost\n",
        "        J = total_cost(J_content, J_style, alpha = content_weight, beta= style_weight )\n",
        "        \n",
        "    grad = tape.gradient(J, generated_image)\n",
        "    optimizer.apply_gradients([(grad, generated_image)])\n",
        "    generated_image.assign(clip_0_1(generated_image))\n",
        "    return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk2gDikma2ZV"
      },
      "source": [
        "#initializing the generated image from content image :)\n",
        "\n",
        "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
        "imshow(generated_image.numpy()[0])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_-Qmfo7SQhK"
      },
      "source": [
        "# If I load stored image progress from a previous training : change myStoredImage.jpg to your  image\n",
        "# temp_generated_image = np.array(Image.open(\"myStoredImage.jpg\").resize((img_size, img_size)))\n",
        "# temp_generated_image = tf.constant(np.reshape(temp_generated_image, ((1,) + temp_generated_image.shape)))\n",
        "# generated_image = tf.Variable(tf.image.convert_image_dtype(temp_generated_image, tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVgxU7CGSjNb"
      },
      "source": [
        "#test one step\n",
        "train_step(generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewMIZVB_Qszo"
      },
      "source": [
        "# Show the generated image at some epochs\n",
        "# !!! to reset the style transfer process. You will need to compile the train_step function again !!!\n",
        "epochs = 12001\n",
        "for i in range(epochs):\n",
        "    J = train_step(generated_image)\n",
        "    if i % 250 == 0:\n",
        "        historyCost.append(float(J))\n",
        "        print(f\"Epoch {i} \")\n",
        "    if i % 250 == 0:\n",
        "        image = tensor_to_image(generated_image)\n",
        "        imshow(image)\n",
        "        image.save(f\"output/imagev40_{i}.jpg\")\n",
        "        plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TmNKyKvTQszp"
      },
      "source": [
        "# Show the 3 images in a row\n",
        "fig = plt.figure(figsize=(16, 4))\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "imshow(content_image[0])\n",
        "ax.title.set_text('Content image')\n",
        "ax = fig.add_subplot(1, 3, 2)\n",
        "imshow(style_image[0])\n",
        "ax.title.set_text('Style image')\n",
        "ax = fig.add_subplot(1, 3, 3)\n",
        "imshow(generated_image[0])\n",
        "ax.title.set_text('Generated image')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieq5rfHBZB02"
      },
      "source": [
        "#showing cost evolution \n",
        "historyCost = [x for x in historyCost if x <= 3]\n",
        "plt.plot(historyCost)\n",
        "plt.show()\n",
        "np.savetxt(\"historycost.csv\", historyCost, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o5Y1Cdkfjza"
      },
      "source": [
        "#historyCost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVNsngBhvNdO"
      },
      "source": [
        "#  download output images\n",
        "#  !zip -r /content/output.zip /content/output\n",
        "#  from google.colab import files\n",
        "#  files.download(\"/content/output.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}